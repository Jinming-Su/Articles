---
title: 2模型评估与选择
date: 2017-03-16 00:00:01
categories:
- Machine_Learning
- ZhouZhihua
tags:
- machinelearning
description: 关于周志华《机器学习》学习过程中的笔记
---

### 2

### 评估方法
通常，我们可通过实验测试来对学习器的泛华误差进行评估，并进而做出选择.通常使用测试集的测试误差做为泛化误差的近似。  
**从一个包含m个样例的数据集D中，产生训练集S和测试集T的常用方法**:  
**(1)留出法(hold-out)**  
直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，即`D=S并T，S交T=空集`.  
注意:1.训练集与测试集的划分应该尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响.例如采用"分层采样".  2.即使使用分层采样，不同的划分仍将导致不同的训练集和测试集，比如对排序后的样本进行划分，取前一部分和后一部分的影响可能会不同，模型评估的结果也会不同.因此，单次使用留出法得到的估计结果往往不够稳定可靠，故一般采用若干次随机的划分，重复进行实验评估后取平均值，作为留出法的评估结果.  
**(2)交叉验证法(cross validation)**  
先将数据集D划分为k个大小相似的互斥子集，即`D=D1并D2并...并Dk，Di交Dj=空集(i!=j)`.其中每个子集Di都尽可能爆出数据分布的一致性，即从D中通过分层采样得到.然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集;一共进行k次训练和测试，最后返回的是这k个测试结果的均值.  
**k折交叉验证(k-fold)**：通常把交叉验证法成为“k折交叉验证法”，原因是交叉验证法评估结果的稳定性和保真性在很大程度上取决于k的取值，k的最常用的取值是10.  
**留一法(Leave-One-Out)**:另k=m时，得到交叉验证法的一个特例——“留一法”.留一法的评估结果往往被认为比较准确，然而当数据集比较大是，计算开销会很大(若考虑调参则计算开销更大).
**(3)自助法(Bootstrapping)**  
由于留出法和交叉验证法均保留一部分样本用于测试，导致实际评估的模型所使用的训练集比D小，将引入因训练样本规模不同而导致的估计偏差。而留一法复杂度又太高了，因此我们需要找一种方法能够减少训练样本规模不同造成的影响，同事还能比较高效地进行实验估计.  
**原理**: 直接以自助采用法(又称“可重复采样”或“有放回采样”)为基础，给定包含m个样本的数据集D，采样产生数据集D':每次随机从D中挑选一个样本，将其拷贝放入D'，然后再将该样本返回初始数据集D中，使得该样本在下次采样时仍有可能被采到；重复m次后就到了包含m个样本(样本可能重复)的D'.样本在m次采样使用不被采到的概率为(1-1/m)^m，取极限得到lim(1-1/m)^m = 1/e = 0.368.即通过自助采样，初始数据集D中约有36.8%的样本未出现在采样的数据集D'中.这样我们仍然使用m个样本进行训练，仍有约1/3的在训练集中没有出现过的样本用于测试，这样的测试结果，亦称“包外估计”(out-og-bag estimate).  
**优缺点**: 自助法在数据集较小、难以有效划分训练/测试集时很有用.此外，自助发能够才初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处，然而，自助发产生的数据集改变了初始数据集的分布，这回引导误差偏差，因此在数据量足够时，留出法和交叉验证法更常用一些.  

### 性能度量  
对学习器的泛化性能进行评估，不仅需要有效可行的实验评估方法，还需要有衡量模型泛化能力的评估标准，这就是性能度量.  
**(1)错误率与精度**  
错误率定义为：分类错误的样本数占样本总数的比例.数学形式是: E(f;D) = 1/m sum I(f(xi) != yi). I(x)是指示函数，x为真则I(x)=1，x为假则I(x)=0.  
精度定义为：分类正确的样本数占样本总数的比例.容易得到acc(f;D) = 1 - E(f; D).  
**(2)查准率、查全率与F1**  
对于二分类问题，分类结果混淆矩阵如下:  
![1](https://cloud.githubusercontent.com/assets/16068384/23979352/029e7f18-0a34-11e7-9ef8-504eda19f200.png)  
查准率: P = TP/(TP + FP)  
查全率: R = TP/(TP + FN)  
查准率和查全率是一对矛盾的度量.一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低.  
**PR曲线**:在很多情况下，可以根据学习器的预测结果对样例进行排序，排在前面的是学习器认为“最可能”是正例的样本，排在最后的则是学习期认为“最不可能”是正例的样本.按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率.以查准率为纵轴、查全率为
